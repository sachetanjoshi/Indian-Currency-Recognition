{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from scipy.spatial import distance as dist\n",
    "import imutils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.util import img_as_float\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "from skimage.feature import hog\n",
    "from skimage import exposure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from sklearn import svm, metrics, datasets\n",
    "from sklearn.utils import Bunch\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_canny(image, sigma=0.33):\n",
    "    \n",
    "    # compute the median of the single channel pixel intensities\n",
    "    v = np.median(image)\n",
    "    \n",
    "    # apply automatic Canny edge detection using the computed median\n",
    "    lower = int(max(0, (1.0 - sigma) * v))\n",
    "    upper = int(min(255, (1.0 + sigma) * v))\n",
    "    edged = cv2.Canny(image, lower, upper)\n",
    "    \n",
    "    # return the edged image\n",
    "    return edged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_points(pts):\n",
    "    # sort the points based on their x-coordinates\n",
    "    xSorted = pts[np.argsort(pts[:, 0]), :]\n",
    "    \n",
    "    # grab the left-most and right-most points from the sorted\n",
    "    # x-roodinate points\n",
    "    leftMost = xSorted[:2, :]\n",
    "    rightMost = xSorted[2:, :]\n",
    "    \n",
    "    # now, sort the left-most coordinates according to their\n",
    "    # y-coordinates so we can grab the top-left and bottom-left\n",
    "    # points, respectively\n",
    "    leftMost = leftMost[np.argsort(leftMost[:, 1]), :]\n",
    "    (tl, bl) = leftMost\n",
    "    \n",
    "    # now that we have the top-left coordinate, use it as an\n",
    "    # anchor to calculate the Euclidean distance between the\n",
    "    # top-left and right-most points; by the Pythagorean\n",
    "    # theorem, the point with the largest distance will be\n",
    "    # our bottom-right point\n",
    "    D = dist.cdist(tl[np.newaxis], rightMost, \"euclidean\")[0]\n",
    "    (br, tr) = rightMost[np.argsort(D)[::-1], :]\n",
    "    \n",
    "    # return the coordinates in top-left, top-right,\n",
    "    # bottom-right, and bottom-left order\n",
    "    return np.array([tl, tr, br, bl], dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def four_point_transform(image, pts):\n",
    "    \n",
    "    # obtain a consistent order of the points and unpack them\n",
    "    # individually\n",
    "    rect = order_points(pts)\n",
    "    (tl, tr, br, bl) = rect\n",
    "    \n",
    "    # compute the width of the new image, which will be the\n",
    "    # maximum distance between bottom-right and bottom-left\n",
    "    # x-coordiates or the top-right and top-left x-coordinates\n",
    "    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
    "    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
    "    maxWidth = max(int(widthA), int(widthB))\n",
    "    \n",
    "    # compute the height of the new image, which will be the\n",
    "    # maximum distance between the top-right and bottom-right\n",
    "    # y-coordinates or the top-left and bottom-left y-coordinates\n",
    "    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
    "    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
    "    maxHeight = max(int(heightA), int(heightB))\n",
    "    \n",
    "    # now that we have the dimensions of the new image, construct\n",
    "    # the set of destination points to obtain a \"birds eye view\",\n",
    "    # (i.e. top-down view) of the image, again specifying points\n",
    "    # in the top-left, top-right, bottom-right, and bottom-left\n",
    "    # order\n",
    "    dst = np.array([\n",
    "        [0, 0],\n",
    "        [maxWidth - 1, 0],\n",
    "        [maxWidth - 1, maxHeight - 1],\n",
    "        [0, maxHeight - 1]], dtype = \"float32\")\n",
    "  \n",
    "    # compute the perspective transform matrix and then apply it\n",
    "    M = cv2.getPerspectiveTransform(rect, dst)\n",
    "    warped = cv2.warpPerspective(image, M, (maxWidth, maxHeight))\n",
    "    \n",
    "    # return the warped image\n",
    "    return warped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image):\n",
    "    #image = cv2.imread('train_image/4/30.jpg')\n",
    "    ratio = image.shape[0] / 500.0\n",
    "    orig = image.copy()\n",
    "    image = imutils.resize(image, height = 500)\n",
    "\n",
    "\n",
    "    # convert the image to grayscale, blur it, and find edges\n",
    "    # in the image\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (7, 7), 0)\n",
    "    edged = auto_canny(gray)\n",
    "    edged = cv2.dilate(edged, None, iterations=1)\n",
    "    edged = cv2.erode(edged, None, iterations=1)\n",
    "\n",
    "    \"\"\"plt.figure(figsize=(15,15))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(image)\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(edged,cmap='gray')\n",
    "    print(image.shape)\"\"\"\n",
    "    \n",
    "    cnts = cv2.findContours(edged.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "    cnts = sorted(cnts, key = cv2.contourArea, reverse = True)[:5]\n",
    "\n",
    "    # loop over the contours\n",
    "    flag=0\n",
    "    for c in cnts:\n",
    "        # approximate the contour\n",
    "        peri = cv2.arcLength(c, True)\n",
    "        approx = cv2.approxPolyDP(c, 0.02 * peri, True)\n",
    "\n",
    "        # if our approximated contour has four points, then we\n",
    "        # can assume that we have found our screen\n",
    "        if len(approx) == 4:\n",
    "            screenCnt = approx\n",
    "            flag=1\n",
    "            break\n",
    "\n",
    "        # show the contour (outline) of the piece of paper\n",
    "    if flag!=0:\n",
    "        print(\"STEP 2: Find contours of paper\")\n",
    "        im=cv2.drawContours(image, [screenCnt], -1, (0, 255, 0), 2)\n",
    "        \n",
    "        #plt.imshow(im)\n",
    "        \n",
    "        warped = four_point_transform(orig, screenCnt.reshape(4, 2) * ratio)\n",
    "\n",
    "        # show the original and scanned images\n",
    "        print(\"STEP 3: Apply perspective transform\")\n",
    "        #orig=imutils.resize(orig, height = 650)\n",
    "        #warped=imutils.resize(warped, height = 650)\n",
    "        orig=cv2.resize(orig, (500, 500),interpolation = cv2.INTER_NEAREST) \n",
    "        warped=cv2.resize(warped, (500, 500),interpolation = cv2.INTER_NEAREST) \n",
    "\n",
    "        \"\"\"plt.figure(figsize=(12,12))\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.imshow(orig)\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.imshow(warped)\n",
    "        print(warped.shape)\"\"\"\n",
    "        \n",
    "        return warped\n",
    "    \n",
    "    else:\n",
    "        return orig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(image):\n",
    "    warped=preprocess(image)\n",
    "    feature = []\n",
    "    \n",
    "    #ORB\n",
    "    orb = cv2.ORB_create(nfeatures=3000)\n",
    "    image_train=cv2.cvtColor(warped,cv2.COLOR_BGR2GRAY)\n",
    "    kp_logo, des_logo = orb.detectAndCompute(image_train, None)\n",
    "    result_image_train = cv2.drawKeypoints(image_train, kp_logo, None, flags=0)\n",
    "    \n",
    "    \"\"\"\"plt.figure(figsize=(9,9))\n",
    "    plt.imshow(result_image_train,cmap='gray')\"\"\"\n",
    "    \n",
    "    desc=des_logo\n",
    "    desc=img_as_float(desc)\n",
    "    d=desc.flatten()\n",
    "    feature.append(d)\n",
    "    \n",
    "    #HOG\n",
    "    resized_img = resize(warped, (256,512)) \n",
    "    fd, hog_image = hog(resized_img, orientations=9, pixels_per_cell=(8, 8), \n",
    "                    cells_per_block=(2, 2), visualize=True, multichannel=True)\n",
    "    hog_image_rescaled = exposure.rescale_intensity(hog_image, in_range=(0, 10)) \n",
    "    \n",
    "    \"\"\"\"plt.imshow(hog_image,cmap='gray')\"\"\"\n",
    "        \n",
    "    feature.append(fd)\n",
    "    \n",
    "    \n",
    "    return d,fd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_files(container_path):\n",
    "    \"\"\"\n",
    "    Load image files with categories as subfolder names \n",
    "    which performs like scikit-learn sample dataset\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    container_path : string or unicode\n",
    "        Path to the main folder holding one subfolder per category\n",
    "    dimension : tuple\n",
    "        size to which image are adjusted to\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Bunch\n",
    "    \"\"\"\n",
    "    image_dir = Path(container_path)\n",
    "    folders = [directory for directory in image_dir.iterdir() if directory.is_dir()]\n",
    "    categories = [fo.name for fo in folders]\n",
    "\n",
    "    descr = \"A image classification dataset\"\n",
    "    images = []\n",
    "    flat_data = []\n",
    "    target = []\n",
    "    for i, direc in enumerate(folders):\n",
    "        for file in direc.iterdir():\n",
    "            d,fd=feature_extraction()\n",
    "            F=np.concatenate([d,fd])\n",
    "            flat_data.append(F) \n",
    "            #flat_data.append(img.flatten()) \n",
    "            #images.append(img_resized)\n",
    "            #images.append(img)\n",
    "            target.append(int(direc.name))\n",
    "    flat_data = np.array(flat_data)\n",
    "    flat_data = scaler.fit_transform(flat_data)\n",
    "    target = np.array(target)\n",
    "    #images2 = np.array(images)\n",
    "\n",
    "    return Bunch(data=flat_data,\n",
    "                 target=target,\n",
    "                 target_names=categories,\n",
    "                 #images=images2,\n",
    "                 #list_im=images,\n",
    "                 DESCR=descr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 2: Find contours of paper\n",
      "STEP 3: Apply perspective transform\n",
      "STEP 2: Find contours of paper\n",
      "STEP 3: Apply perspective transform\n",
      "STEP 2: Find contours of paper\n",
      "STEP 3: Apply perspective transform\n",
      "STEP 2: Find contours of paper\n",
      "STEP 3: Apply perspective transform\n",
      "STEP 2: Find contours of paper\n",
      "STEP 3: Apply perspective transform\n",
      "STEP 2: Find contours of paper\n",
      "STEP 3: Apply perspective transform\n",
      "STEP 2: Find contours of paper\n",
      "STEP 3: Apply perspective transform\n",
      "STEP 2: Find contours of paper\n",
      "STEP 3: Apply perspective transform\n",
      "STEP 2: Find contours of paper\n",
      "STEP 3: Apply perspective transform\n",
      "STEP 2: Find contours of paper\n",
      "STEP 3: Apply perspective transform\n",
      "STEP 2: Find contours of paper\n",
      "STEP 3: Apply perspective transform\n",
      "STEP 2: Find contours of paper\n",
      "STEP 3: Apply perspective transform\n",
      "STEP 2: Find contours of paper\n",
      "STEP 3: Apply perspective transform\n",
      "STEP 2: Find contours of paper\n",
      "STEP 3: Apply perspective transform\n",
      "STEP 2: Find contours of paper\n",
      "STEP 3: Apply perspective transform\n",
      "STEP 2: Find contours of paper\n",
      "STEP 3: Apply perspective transform\n",
      "STEP 2: Find contours of paper\n",
      "STEP 3: Apply perspective transform\n",
      "STEP 2: Find contours of paper\n",
      "STEP 3: Apply perspective transform\n",
      "STEP 2: Find contours of paper\n",
      "STEP 3: Apply perspective transform\n",
      "STEP 2: Find contours of paper\n",
      "STEP 3: Apply perspective transform\n",
      "STEP 2: Find contours of paper\n",
      "STEP 3: Apply perspective transform\n",
      "STEP 2: Find contours of paper\n",
      "STEP 3: Apply perspective transform\n",
      "STEP 2: Find contours of paper\n",
      "STEP 3: Apply perspective transform\n",
      "STEP 2: Find contours of paper\n",
      "STEP 3: Apply perspective transform\n",
      "STEP 2: Find contours of paper\n",
      "STEP 3: Apply perspective transform\n",
      "STEP 2: Find contours of paper\n",
      "STEP 3: Apply perspective transform\n",
      "STEP 2: Find contours of paper\n",
      "STEP 3: Apply perspective transform\n",
      "STEP 2: Find contours of paper\n",
      "STEP 3: Apply perspective transform\n",
      "STEP 2: Find contours of paper\n",
      "STEP 3: Apply perspective transform\n",
      "STEP 2: Find contours of paper\n",
      "STEP 3: Apply perspective transform\n",
      "STEP 2: Find contours of paper\n",
      "STEP 3: Apply perspective transform\n",
      "STEP 2: Find contours of paper\n",
      "STEP 3: Apply perspective transform\n",
      "STEP 2: Find contours of paper\n",
      "STEP 3: Apply perspective transform\n",
      "STEP 2: Find contours of paper\n",
      "STEP 3: Apply perspective transform\n",
      "STEP 2: Find contours of paper\n",
      "STEP 3: Apply perspective transform\n",
      "STEP 2: Find contours of paper\n",
      "STEP 3: Apply perspective transform\n",
      "STEP 2: Find contours of paper\n",
      "STEP 3: Apply perspective transform\n",
      "STEP 2: Find contours of paper\n",
      "STEP 3: Apply perspective transform\n",
      "STEP 2: Find contours of paper\n",
      "STEP 3: Apply perspective transform\n",
      "STEP 2: Find contours of paper\n",
      "STEP 3: Apply perspective transform\n",
      "STEP 2: Find contours of paper\n",
      "STEP 3: Apply perspective transform\n",
      "STEP 2: Find contours of paper\n",
      "STEP 3: Apply perspective transform\n",
      "STEP 2: Find contours of paper\n",
      "STEP 3: Apply perspective transform\n",
      "STEP 2: Find contours of paper\n",
      "STEP 3: Apply perspective transform\n",
      "STEP 2: Find contours of paper\n",
      "STEP 3: Apply perspective transform\n",
      "STEP 2: Find contours of paper\n",
      "STEP 3: Apply perspective transform\n",
      "STEP 2: Find contours of paper\n",
      "STEP 3: Apply perspective transform\n",
      "STEP 2: Find contours of paper\n",
      "STEP 3: Apply perspective transform\n",
      "STEP 2: Find contours of paper\n",
      "STEP 3: Apply perspective transform\n",
      "STEP 2: Find contours of paper\n",
      "STEP 3: Apply perspective transform\n",
      "STEP 2: Find contours of paper\n",
      "STEP 3: Apply perspective transform\n",
      "STEP 2: Find contours of paper\n",
      "STEP 3: Apply perspective transform\n",
      "STEP 2: Find contours of paper\n",
      "STEP 3: Apply perspective transform\n",
      "STEP 2: Find contours of paper\n",
      "STEP 3: Apply perspective transform\n",
      "STEP 2: Find contours of paper\n",
      "STEP 3: Apply perspective transform\n",
      "STEP 2: Find contours of paper\n",
      "STEP 3: Apply perspective transform\n",
      "STEP 2: Find contours of paper\n",
      "STEP 3: Apply perspective transform\n"
     ]
    }
   ],
   "source": [
    "image_dataset = load_image_files(\"train_image/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57,)\n"
     ]
    }
   ],
   "source": [
    "print(image_dataset.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57, 157828)\n"
     ]
    }
   ],
   "source": [
    "print(image_dataset.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data = image_dataset.data\n",
    "labels = image_dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "combined = list(zip(image_data, labels))\n",
    "random.shuffle(combined)\n",
    "\n",
    "image_data[:], labels[:] = zip(*combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57, 157828)\n",
      "(57,)\n"
     ]
    }
   ],
   "source": [
    "print(image_data.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_classes = len(np.unique(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classWiseData(x, y):\n",
    "    data = {}\n",
    "    \n",
    "    for i in range(number_of_classes):\n",
    "        data[i] = []\n",
    "        \n",
    "    for i in range(x.shape[0]):\n",
    "        data[y[i]].append(x[i])\n",
    "        \n",
    "    for k in data.keys():\n",
    "        data[k] = np.array(data[k])\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = classWiseData(image_data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "8\n",
      "11\n",
      "14\n",
      "7\n",
      "7\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(data[0].shape[0])\n",
    "print(data[1].shape[0])\n",
    "print(data[2].shape[0])\n",
    "print(data[3].shape[0])\n",
    "print(data[4].shape[0])\n",
    "print(data[5].shape[0])\n",
    "print(data[6].shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM:\n",
    "    def __init__(self,C=1.0):\n",
    "        self.C = C\n",
    "        self.W = 0\n",
    "        self.b = 0\n",
    "        \n",
    "    def hingeLoss(self,W,b,X,Y):\n",
    "        loss  = 0.0\n",
    "        \n",
    "        loss += .5*np.dot(W,W.T)\n",
    "        \n",
    "        m = X.shape[0]\n",
    "        \n",
    "        for i in range(m):\n",
    "            ti = Y[i]*(np.dot(W,X[i].T)+b)\n",
    "            loss += self.C *max(0,(1-ti))\n",
    "            \n",
    "        return loss[0][0]\n",
    "    \n",
    "    def fit(self,X,Y,batch_size=50,learning_rate=0.001,maxItr=500):\n",
    "        \n",
    "        no_of_features = X.shape[1]\n",
    "        no_of_samples = X.shape[0]\n",
    "        \n",
    "        n = learning_rate\n",
    "        c = self.C\n",
    "        \n",
    "        #Init the model parameters\n",
    "        W = np.zeros((1,no_of_features))\n",
    "        bias = 0\n",
    "        \n",
    "        #Initial Loss\n",
    "        \n",
    "        #Training from here...\n",
    "        # Weight and Bias update rule\n",
    "        losses = []\n",
    "        \n",
    "        for i in range(maxItr):\n",
    "            #Training Loop\n",
    "            \n",
    "            l = self.hingeLoss(W,bias,X,Y)\n",
    "            losses.append(l)\n",
    "            ids = np.arange(no_of_samples)\n",
    "            np.random.shuffle(ids)\n",
    "            \n",
    "            #Batch Gradient Descent(Paper) with random shuffling\n",
    "            for batch_start in range(0,no_of_samples,batch_size):\n",
    "                #Assume 0 gradient for the batch\n",
    "                gradw = 0\n",
    "                gradb = 0\n",
    "                \n",
    "                #Iterate over all examples in the mini batch\n",
    "                for j in range(batch_start,batch_start+batch_size):\n",
    "                    if j<no_of_samples:\n",
    "                        i = ids[j]\n",
    "                        ti =  Y[i]*(np.dot(W,X[i].T)+bias)\n",
    "                        \n",
    "                        if ti>1:\n",
    "                            gradw += 0\n",
    "                            gradb += 0\n",
    "                        else:\n",
    "                            gradw += c*Y[i]*X[i]\n",
    "                            gradb += c*Y[i]\n",
    "                            \n",
    "                #Gradient for the batch is ready! Update W,B\n",
    "                W = W - n*W + n*gradw\n",
    "                bias = bias + n*gradb\n",
    "                \n",
    "        \n",
    "        self.W = W\n",
    "        self.b = bias\n",
    "        return W,bias,losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Combines data of two classes into a single matrix\"\"\"\n",
    "def getDataPairForSVM(d1,d2):\n",
    "    \n",
    "    l1,l2 = d1.shape[0], d2.shape[0]\n",
    "    samples = l1+l2\n",
    "    features = d1.shape[1]\n",
    "    \n",
    "    data_pair = np.zeros((samples,features))\n",
    "    data_labels = np.zeros((samples,))\n",
    "    \n",
    "    data_pair[:l1,:] = d1\n",
    "    data_pair[l1:,:] = d2\n",
    "    \n",
    "    data_labels[:l1] = -1\n",
    "    data_labels[l1:] = 1\n",
    "    \n",
    "    return data_pair, data_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mySVM = SVM()\n",
    "xp, yp = getDataPairForSVM(data[0], data[2])\n",
    "w,b,loss = mySVM.fit(xp,yp,learning_rate=0.00001,maxItr=1000)\n",
    "plt.plot(loss)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainSVMs(x,y):\n",
    "    svm_classifiers = {}\n",
    "    \n",
    "    for i in range(number_of_classes):\n",
    "        svm_classifiers[i] = {}\n",
    "        for j in range(i+1, number_of_classes):\n",
    "            xpair,ypair = getDataPairForSVM(data[i],data[j])\n",
    "            wts,b,loss = mySVM.fit(xpair, ypair,learning_rate=0.00001,maxItr=1000)\n",
    "            svm_classifiers[i][j] = (wts,b)\n",
    "            \n",
    "            plt.plot(loss)\n",
    "            plt.show()\n",
    "            \n",
    "    return svm_classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-0077ea343297>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msvm_classifiers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainSVMs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-62-14253a1af075>\u001b[0m in \u001b[0;36mtrainSVMs\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[0mxpair\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mypair\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetDataPairForSVM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m             \u001b[0mwts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmySVM\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxpair\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mypair\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.00001\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmaxItr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m             \u001b[0msvm_classifiers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mwts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-54-e7c345451103>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, Y, batch_size, learning_rate, maxItr)\u001b[0m\n\u001b[0;32m     60\u001b[0m                             \u001b[0mgradb\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m                         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m                             \u001b[0mgradw\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m                             \u001b[0mgradb\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "svm_classifiers = trainSVMs(image_data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
